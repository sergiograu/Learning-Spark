{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3eb99d",
   "metadata": {},
   "source": [
    "#### PYTHON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284fe31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c23c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd704c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"Ejemplo4\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e308e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file= \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/departuredelays.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5a154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "     .option(\"header\", \"true\")\n",
    "     .option(\"inferSchema\", \"true\")\n",
    "     .load(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db84040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb97fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT distance, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE distance > 1000\n",
    "ORDER BY distance DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70117064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(\"distance\", \"origin\", \"destination\").where(col(\"distance\")>1000).orderBy(desc(\"distance\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e52569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "|    4330|   JFK|        HNL|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(\"distance\", \"origin\", \"destination\").where(\"distance>1000\").orderBy(\"distance\", ascending=False).show(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570619df",
   "metadata": {},
   "source": [
    "Se ha sacado la misma tabla de 3 formas distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8314cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|2190925| 1638|   SFO|        ORD|\n",
      "|1031755|  396|   SFO|        ORD|\n",
      "|1022330|  326|   SFO|        ORD|\n",
      "|1051205|  320|   SFO|        ORD|\n",
      "|1190925|  297|   SFO|        ORD|\n",
      "|2171115|  296|   SFO|        ORD|\n",
      "|1071040|  279|   SFO|        ORD|\n",
      "|1051550|  274|   SFO|        ORD|\n",
      "|3120730|  266|   SFO|        ORD|\n",
      "|1261104|  258|   SFO|        ORD|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE delay > 120 AND origin = 'SFO' AND destination = 'ORD'\n",
    "ORDER BY delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2e2112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|2190925| 1638|   SFO|        ORD|\n",
      "|3020700| 1592|   RSW|        ORD|\n",
      "|2210630| 1511|   MCO|        ORD|\n",
      "|2201215| 1238|   BOS|        ORD|\n",
      "|1181225| 1151|   PBI|        ORD|\n",
      "|2111225| 1128|   PBI|        ORD|\n",
      "|2051715| 1009|   OKC|        ORD|\n",
      "|3310645| 1006|   RSW|        ORD|\n",
      "|3191420|  994|   SJC|        ORD|\n",
      "|3300645|  987|   RSW|        ORD|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(\"date\", \"delay\", \"origin\", \"destination\").where((\"delay > 1000\") and (\"origin = 'SFO'\") and (\"destination = 'ORD'\")).orderBy(\"delay\", ascending = False).show(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487f6872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+-------------+\n",
      "|delay|origin|destination|Flight_Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "|  333|   ABE|        ATL|  Long Delays|\n",
      "|  305|   ABE|        ATL|  Long Delays|\n",
      "|  275|   ABE|        ATL|  Long Delays|\n",
      "|  257|   ABE|        ATL|  Long Delays|\n",
      "|  247|   ABE|        DTW|  Long Delays|\n",
      "|  247|   ABE|        ATL|  Long Delays|\n",
      "|  219|   ABE|        ORD|  Long Delays|\n",
      "|  211|   ABE|        ATL|  Long Delays|\n",
      "|  197|   ABE|        DTW|  Long Delays|\n",
      "|  192|   ABE|        ORD|  Long Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT delay, origin, destination,\n",
    " CASE\n",
    " WHEN delay > 360 THEN 'Very Long Delays'\n",
    " WHEN delay > 120 AND delay < 360 THEN 'Long Delays'\n",
    " WHEN delay > 60 AND delay < 120 THEN 'Short Delays'\n",
    " WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays'\n",
    " WHEN delay = 0 THEN 'No Delays'\n",
    " ELSE 'Early'\n",
    " END AS Flight_Delays\n",
    " FROM us_delay_flights_tbl\n",
    " ORDER BY origin, delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18712466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE DATABASE learn_spark_db3\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cdd08fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"USE learn_spark_db3\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba61427",
   "metadata": {},
   "source": [
    "Creating managed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c55fa23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE managed_us_delay_flights_tbl (date STRING, delay INT, distance INT, origin STRING, destination STRING)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0218b0b",
   "metadata": {},
   "source": [
    "Creating unmanaged table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52709488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE TABLE us_delay_flights_tbl(date STRING, delay INT, distance INT, origin STRING, destination STRING) USING csv OPTIONS(PATH 'C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/departuredelays.csv')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa36f776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE GLOBAL TEMP VIEW us_origin_airport_SFO_global_tmp_view AS SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'SFO' \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6228ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMP VIEW us_origin_airport_JFK_tmp_view AS SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'JFK' \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c60e8c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: int, delay: int, origin: string, destination: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_origin_airport_JFK_tmp_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02c7dea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: int, delay: int, origin: string, destination: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM global_temp.us_origin_airport_SFO_global_tmp_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3050bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP VIEW IF EXISTS us_origin_airport_SFO_global_tmp_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95bc7a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP VIEW IF EXISTS us_origin_airport_JFK_tmp_view\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f3bd5",
   "metadata": {},
   "source": [
    "Reading tables into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0fc08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_flights_df = spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a633718",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_flights_df2 = spark.table(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0145e",
   "metadata": {},
   "source": [
    "##### PARQUET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a352d92",
   "metadata": {},
   "source": [
    "Reading parquet file into a Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9ab959a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMP VIEW us_delay_flights_tbl USING parquet OPTIONS(PATH \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04a13689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35ceb76",
   "metadata": {},
   "source": [
    "Writing DataFrames to Spark SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f249af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write.mode(\"overwrite\").saveAsTable(\"us_delay_flights_tbl1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e49d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|2151800|  108|     290|   ORD|        MSP|\n",
      "|2151800|  142|     772|   ORD|        DEN|\n",
      "|2151303|   16|    1516|   ORD|        LAX|\n",
      "|2151157|    7|    1316|   ORD|        LAS|\n",
      "|2151818|   55|    1511|   ORD|        PDX|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl1\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c4b14",
   "metadata": {},
   "source": [
    "##### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab03d68",
   "metadata": {},
   "source": [
    "Reading a JSON file into a Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "087615c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl USING json OPTIONS(PATH \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/json/*\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7728dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63468070",
   "metadata": {},
   "source": [
    "##### CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a62d6e",
   "metadata": {},
   "source": [
    "Reading a CSV file into a Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19f3b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl USING csv OPTIONS(PATH \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/csv/*\", header \"true\", inferSchema \"true\", mode \"FAILFAST\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9bc777bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f34818",
   "metadata": {},
   "source": [
    "##### AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de2099",
   "metadata": {},
   "source": [
    "Reading an Avro file into a Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99c674ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW episode_tbl USING avro OPTIONS(PATH \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\" )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca76b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SELECT * FROM episode_tbl\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "013d0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = (spark.read.format(\"avro\").load(\"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d10f7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82429666",
   "metadata": {},
   "source": [
    "##### ORC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638c165",
   "metadata": {},
   "source": [
    "Reading an Orc file into a Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9413b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl USING orc OPTIONS(PATH \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/flights/summary-data/orc/*\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01073eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9590a",
   "metadata": {},
   "source": [
    "##### IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8d28b",
   "metadata": {},
   "source": [
    "Reading an image file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c6a7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af05044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/cctvVideos/train_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10851c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df=spark.read.format(\"image\").load(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5348d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f5c9d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----+-----+\n",
      "|height|width|nChannels|mode|label|\n",
      "+------+-----+---------+----+-----+\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |1    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "+------+-----+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\", \"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0efc64",
   "metadata": {},
   "source": [
    "##### BINARY FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c87328",
   "metadata": {},
   "source": [
    "Reading a binary file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aecdcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/cctvVideos/train_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0644c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_files_df = (spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.jpg\").load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b5af55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "|                path|   modificationTime|length|             content|label|\n",
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "|file:/C:/Learning...|2021-04-15 02:34:17| 55037|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Learning...|2021-04-15 02:34:17| 54634|[FF D8 FF E0 00 1...|    1|\n",
      "|file:/C:/Learning...|2021-04-15 02:34:17| 54624|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Learning...|2021-04-15 02:34:17| 54505|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/C:/Learning...|2021-04-15 02:34:17| 54475|[FF D8 FF E0 00 1...|    0|\n",
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_files_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
