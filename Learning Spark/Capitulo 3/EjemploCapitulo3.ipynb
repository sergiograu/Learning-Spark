{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bafcc0e",
   "metadata": {},
   "source": [
    "# CAPITULO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5af0f5",
   "metadata": {},
   "source": [
    "# PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7009d3",
   "metadata": {},
   "source": [
    "Hay dos manera para definir un esquema.        \n",
    "La primera es definir un esquema porgramaticamente para Dataframe con tres columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b67526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fba1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    "                    StructField(\"title\", StringType(), False),\n",
    "                    StructField(\"pages\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d0dc7",
   "metadata": {},
   "source": [
    "La segunda es usando DDL (Data definition Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a263277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccf908",
   "metadata": {},
   "source": [
    "Ejemplo 2 -- Rellenando la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb3f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7115d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "esquema = \"ID INT, First STRING, Last STRING, URL STRING, Published STRING, Hits INT, Campaigns ARRAY<STRING>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde02578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "      [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "      [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "      [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568,[\"twitter\", \"FB\"]],\n",
    "      [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "      [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94bbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"Ejemplo.2\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a9a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_df=spark.createDataFrame(data, esquema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9340377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|ID |First    |Last   |URL              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|1/4/2016 |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|5/5/2018 |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|6/7/2019 |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|5/12/2018|10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|3/2/2015 |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\n",
      "La tabla tiene 6 filas\n"
     ]
    }
   ],
   "source": [
    "blogs_df.show(truncate=False)\n",
    "print(\"La tabla tiene %d filas\" % (blogs_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e980a0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- URL: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a746f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(ID,IntegerType,true),StructField(First,StringType,true),StructField(Last,StringType,true),StructField(URL,StringType,true),StructField(Published,StringType,true),StructField(Hits,IntegerType,true),StructField(Campaigns,ArrayType(StringType,true),true)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7e14a",
   "metadata": {},
   "source": [
    "Ejercicios proyecciones y filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3e78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68446ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1857662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38f2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40263b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"Ejemplo.3\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_file = \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ab158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df = (spark.read.format(\"csv\")\n",
    "          .option(\"header\", \"true\")\n",
    "          .option(\"inferSchema\", \"true\")\n",
    "          .load(fire_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f00d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_fire_df = (fire_df.select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\").where(fire_df.CallType != \"Medical Incident\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea58ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "|2003304       |01/11/2002 09:58:53 AM|Alarms        |\n",
      "|2003382       |01/11/2002 02:59:04 PM|Structure Fire|\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire|\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire|\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire|\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576a87c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        CallType|\n",
      "+----------------+\n",
      "|  Structure Fire|\n",
      "|Medical Incident|\n",
      "+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"CallType\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec00d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df.select(\"CallType\").where(fire_df.CallType.isNotNull()).agg(countDistinct(\"CallType\").alias(\"DistinctCallTypes\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdcac1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|CallType                           |\n",
      "+-----------------------------------+\n",
      "|Elevator / Escalator Rescue        |\n",
      "|Marine Fire                        |\n",
      "|Aircraft Emergency                 |\n",
      "|Confined Space / Structure Collapse|\n",
      "|Administrative                     |\n",
      "|Alarms                             |\n",
      "|Odor (Strange / Unknown)           |\n",
      "|Citizen Assist / Service Call      |\n",
      "|HazMat                             |\n",
      "|Watercraft in Distress             |\n",
      "+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df.select(\"CallType\").where(fire_df.CallType.isNotNull()).distinct().show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670f0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04595fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fire_df.select(\"ResponseDelayedinMins\").where(new_fire_df.ResponseDelayedinMins>5).show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74634f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_ts_df = (new_fire_df.withColumn(\"IncidentDate\", to_timestamp(new_fire_df.CallDate, \"MM/dd/yyyy\")).drop(\"CallDate\").withColumn(\"OnWatchDate\", to_timestamp(new_fire_df.WatchDate, \"MM/dd/yyyy\")).drop(\"WatchDate\").withColumn(\"AvailableDtTs\", to_timestamp(new_fire_df.AvailableDtTm, \"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a263c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTs      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTs\").show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a008a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       IncidentDate|\n",
      "+-------------------+\n",
      "|2000-12-13 00:00:00|\n",
      "|2000-07-18 00:00:00|\n",
      "|2000-12-15 00:00:00|\n",
      "|2000-10-09 00:00:00|\n",
      "|2000-05-17 00:00:00|\n",
      "|2000-05-06 00:00:00|\n",
      "|2000-11-12 00:00:00|\n",
      "|2000-10-07 00:00:00|\n",
      "|2000-10-23 00:00:00|\n",
      "|2000-08-12 00:00:00|\n",
      "|2000-04-22 00:00:00|\n",
      "|2000-08-20 00:00:00|\n",
      "|2000-12-03 00:00:00|\n",
      "|2000-08-01 00:00:00|\n",
      "|2000-06-10 00:00:00|\n",
      "|2000-07-21 00:00:00|\n",
      "|2000-09-04 00:00:00|\n",
      "|2000-08-30 00:00:00|\n",
      "|2000-09-28 00:00:00|\n",
      "|2000-06-27 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"IncidentDate\").distinct().orderBy(year(\"IncidentDate\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c69bf067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"CallType\").where(fire_ts_df.CallType.isNotNull()).groupBy(\"CallType\").count().orderBy(\"count\", ascending = False).show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87a4f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|        3.8923641541750134|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(F.sum(\"NumAlarms\"), F.avg(\"ResponseDelayedinMins\"), F.min(\"ResponseDelayedinMins\"), F.max(\"ResponseDelayedinMins\")).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98bd9e",
   "metadata": {},
   "source": [
    "Generic Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdccc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624fdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Row(350, True, \"Learning Spark 2E\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a7a6bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "826198de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0b026a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning Spark 2E'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b38d0",
   "metadata": {},
   "source": [
    "# SCALA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e4941",
   "metadata": {},
   "source": [
    "Hay dos manera iual que en Python.            \n",
    "La primera es programaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e01875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002861.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1622632040127)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3af295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(author,StringType,false), StructField(title,StringType,false), StructField(pages,IntegerType,false))\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Array(StructField(\"author\", StringType, false),\n",
    "                             StructField(\"title\", StringType, false),\n",
    "                             StructField(\"pages\", IntegerType, false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576542b",
   "metadata": {},
   "source": [
    "La segunda es usando DDL (Data Definition Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c631c78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema1: String = author STRING, title STRING, pages INT\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema1 = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7f929f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002861.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1622644520753)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8a9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbedf006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "esquema: org.apache.spark.sql.types.StructType = StructType(StructField(Id,IntegerType,false), StructField(First,StringType,false), StructField(Last,StringType,false), StructField(Url,StringType,false), StructField(Published,StringType,false), StructField(Hits,IntegerType,false), StructField(Campaigns,ArrayType(StringType,true),false))\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val esquema = StructType(Array(StructField(\"Id\", IntegerType, false),\n",
    " StructField(\"First\", StringType, false),\n",
    " StructField(\"Last\", StringType, false),\n",
    " StructField(\"Url\", StringType, false),\n",
    " StructField(\"Published\", StringType, false),\n",
    " StructField(\"Hits\", IntegerType, false),\n",
    " StructField(\"Campaigns\", ArrayType(StringType), false)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eed1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt: String = C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/blogs.json\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dt = \"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/blogs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef5a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blogsDF: org.apache.spark.sql.DataFrame = [Id: int, First: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val blogsDF = spark.read.schema(esquema).json(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6af6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|Id |First    |Last   |Url              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|1/4/2016 |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|5/5/2018 |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|6/7/2019 |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|5/12/2018|10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|3/2/2015 |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "blogsDF.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9a7f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "println(blogsDF.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aa7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(StructField(Id,IntegerType,true), StructField(First,StringType,true), StructField(Last,StringType,true), StructField(Url,StringType,true), StructField(Published,StringType,true), StructField(Hits,IntegerType,true), StructField(Campaigns,ArrayType(StringType,true),true))\r\n"
     ]
    }
   ],
   "source": [
    "println(blogsDF.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e5243",
   "metadata": {},
   "source": [
    "Ejemplos actuando sobre las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0099b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[String] = Array(Id, First, Last, Url, Published, Hits, Campaigns)\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a313b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.Column = id\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogsDF.col(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3db6b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|(Hits * 2)|Hits|\n",
      "+----------+----+\n",
      "|      9070|4535|\n",
      "|     17816|8908|\n",
      "+----------+----+\n",
      "only showing top 2 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "blogsDF.select((expr(\"Hits * 2\")), col(\"Hits\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a58adba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|(Hits * 2)|Hits|\n",
      "+----------+----+\n",
      "|      9070|4535|\n",
      "|     17816|8908|\n",
      "+----------+----+\n",
      "only showing top 2 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "blogsDF.select((col(\"Hits\") * 2), col(\"Hits\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a27ae4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "blogsDF.withColumn(\"Big Hitters\", (expr(\"Hits > 10000\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f5cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    AuthorsID|\n",
      "+-------------+\n",
      "|  JulesDamji1|\n",
      "| BrookeWenig2|\n",
      "|    DennyLee3|\n",
      "|TathagataDas4|\n",
      "+-------------+\n",
      "only showing top 4 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "blogsDF.withColumn(\"AuthorsID\", (concat(expr(\"First\"), expr(\"Last\"), expr(\"Id\")))).select(col(\"AuthorsID\")).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f7742",
   "metadata": {},
   "source": [
    "Las siguientes funciones devuelven los mismos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "524a95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.select(expr(\"Hits\")).show(2)\n",
    "blogsDF.select(col(\"Hits\")).show(2)\n",
    "blogsDF.select(\"Hits\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535838c",
   "metadata": {},
   "source": [
    "Las dos expresiones sort (sirve para ordenar, en este caso descendentemente), hacen lo mismo solo que en la segunda el caracter $ que convierte el valor Id en una columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5192b3da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; for details, enable `:setting -feature' or `:replay -feature'\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogsDF.sort(col(\"Id\")desc).show()\n",
    "blogsDF.sort($\"Id\".desc).show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b4bdb",
   "metadata": {},
   "source": [
    "Ejemplos actuando sobre filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d344012d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f6aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blogRow: org.apache.spark.sql.Row = [6,Reynold,Xin,https://tinyurl.6,255568,3/2/2015,[Ljava.lang.String;@1b54aea0]\r\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val blogRow = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\", Array(\"twitter\", \"LinkedIn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61299aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res24: Any = Reynold\r\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogRow(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b61796b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows: Seq[(String, String)] = List((Matei Zahara,CA), (Reynold Xin,CA))\r\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows = Seq((\"Matei Zahara\", \"CA\"), (\"Reynold Xin\", \"CA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0961d16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorsDF: org.apache.spark.sql.DataFrame = [Author: string, State: string]\r\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val authorsDF = rows.toDF(\"Author\", \"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60bb1868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|      Author|State|\n",
      "+------------+-----+\n",
      "|Matei Zahara|   CA|\n",
      "| Reynold Xin|   CA|\n",
      "+------------+-----+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "authorsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb09d",
   "metadata": {},
   "source": [
    "Creando un DataSet: para poder crear el DataSer, hay que saber de antemano los tipos de datos que va a contener, el esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755cfc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002861.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1623054334674)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defined class DeviceIoTData\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceIoTData (battery_level: Long, c02_level: Long,\n",
    "cca2: String, cca3: String, cn: String, device_id: Long,\n",
    "device_name: String, humidity: Long, ip: String, latitude: Double,\n",
    "lcd: String, longitude: Double, scale:String, temp: Long,\n",
    "timestamp: Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5110df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds = spark.read.json(\"C:/LearningSparkV2-master/databricks-datasets/learning-spark-v2/iot_devices.json\").as[DeviceIoTData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b674936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|cn           |device_id|device_name          |humidity|ip           |latitude|lcd   |longitude|scale  |temp|timestamp    |\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|8            |868      |US  |USA |United States|1        |meter-gauge-1xbYRYcj |51      |68.161.225.1 |38.0    |green |-97.0    |Celsius|34  |1458444054093|\n",
      "|7            |1473     |NO  |NOR |Norway       |2        |sensor-pad-2n2Pea    |70      |213.161.254.1|62.47   |red   |6.15     |Celsius|11  |1458444054119|\n",
      "|2            |1556     |IT  |ITA |Italy        |3        |device-mac-36TWSKiT  |44      |88.36.5.1    |42.83   |red   |12.83    |Celsius|19  |1458444054120|\n",
      "|6            |1080     |US  |USA |United States|4        |sensor-pad-4mzWkz    |32      |66.39.173.154|44.06   |yellow|-121.32  |Celsius|28  |1458444054121|\n",
      "|4            |931      |PH  |PHL |Philippines  |5        |therm-stick-5gimpUrBB|62      |203.82.41.9  |14.58   |green |120.97   |Celsius|25  |1458444054122|\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "ds.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7c6f9",
   "metadata": {},
   "source": [
    "Operacion con DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47189b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filterTempDS: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val filterTempDS = ds.filter({d => {d.temp > 30 && d.humidity > 70}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82fa8e",
   "metadata": {},
   "source": [
    "filterTempDS.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89ee3c",
   "metadata": {},
   "source": [
    "Otro DataSet mas pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac3aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DeviceTempByCountry\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceTempByCountry(temp: Long, device_name: String, device_id: Long,\n",
    " cca3: String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8debd",
   "metadata": {},
   "source": [
    "val dsTemp = ds .filter(d => {d.temp > 25}) .map(d => (d.temp, d.device_name, d.device_id, d.cca3)) .toDF(\"temp\", \"device_name\", \"device_id\", \"cca3\") .as[DeviceTempByCountry] dsTemp.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3903754",
   "metadata": {},
   "source": [
    "Otra manera de crear el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcdd207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsTemp2: org.apache.spark.sql.Dataset[DeviceTempByCountry] = [temp: bigint, device_name: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsTemp2 = ds\n",
    " .select($\"temp\", $\"device_name\", $\"device_id\", $\"device_id\", $\"cca3\")\n",
    " .where(\"temp > 25\")\n",
    " .as[DeviceTempByCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2c4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+---------+---------+----+\n",
      "|temp|device_name          |device_id|device_id|cca3|\n",
      "+----+---------------------+---------+---------+----+\n",
      "|34  |meter-gauge-1xbYRYcj |1        |1        |USA |\n",
      "|28  |sensor-pad-4mzWkz    |4        |4        |USA |\n",
      "|27  |sensor-pad-6al7RTAobR|6        |6        |USA |\n",
      "|27  |sensor-pad-8xUD6pzsQI|8        |8        |JPN |\n",
      "|26  |sensor-pad-10BsywSYUF|10       |10       |USA |\n",
      "+----+---------------------+---------+---------+----+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "dsTemp2.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0d9ad",
   "metadata": {},
   "source": [
    "Para mirar solo la primera fila del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a56cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device: DeviceTempByCountry = DeviceTempByCountry(34,meter-gauge-1xbYRYcj,1,USA)\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val device = dsTemp2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d09ce0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeviceTempByCountry(34,meter-gauge-1xbYRYcj,1,USA)\r\n"
     ]
    }
   ],
   "source": [
    "println(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d783bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: DeviceTempByCountry = DeviceTempByCountry(34,meter-gauge-1xbYRYcj,1,USA)\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsTemp2.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c94ca7",
   "metadata": {},
   "source": [
    "DataFrames vs Datasets\n",
    "\n",
    "• If you want to tell Spark what to do, not how to do it, use DataFrames or Datasets.     \n",
    "• If you want rich semantics, high-level abstractions, and DSL operators, use DataFrames or Datasets.     \n",
    "• If you want strict compile-time type safety and don’t mind creating multiple case classes for a specific Dataset[T], use Datasets.     \n",
    "• If your processing demands high-level expressions, filters, maps, aggregations, computing averages or sums, SQL queries, columnar access, or use of relational operators on semi-structured data, use DataFrames or Datasets.     \n",
    "• If your processing dictates relational transformations similar to SQL-like queries, use DataFrames.     \n",
    "• If you want to take advantage of and benefit from Tungsten’s efficient serializa‐ tion with Encoders, , use Datasets.     \n",
    "• If you want unification, code optimization, and simplification of APIs across Spark components, use DataFrames.    \n",
    "• If you are an R user, use DataFrames.     \n",
    "• If you are a Python user, use DataFrames and drop down to RDDs if you need more control.     \n",
    "• If you want space and speed efficiency, use DataFrames."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
